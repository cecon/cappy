[
  [
    "doc_1759617927858_up3ub2zwx",
    {
      "id": "doc_1759617927858_up3ub2zwx",
      "title": "README",
      "description": "This document serves as a README file for the TAI ERP assistant project, detailing its features, installation methods, configuration options, and project structure. It provides clear instructions for both local and Docker-based setups, along with environment variable configurations and visual identity assets.",
      "category": "Documentation",
      "tags": [],
      "filePath": "README.md",
      "fileName": "README.md",
      "fileSize": 4431,
      "content": "# TAI - Assistente ERP com Chainlit\r\n\r\nInterface estilo ChatGPT com streaming em tempo real usando Chainlit + Ollama.\r\n\r\n## ğŸš€ CaracterÃ­sticas\r\n\r\n- âœ¨ Interface moderna e responsiva\r\n- ğŸ”„ Streaming em tempo real\r\n- ğŸ¤– IntegraÃ§Ã£o com Ollama\r\n- ğŸ’¬ HistÃ³rico de conversas\r\n- ğŸ¨ Temas personalizÃ¡veis\r\n\r\n## ğŸ“¦ InstalaÃ§Ã£o\r\n\r\n### MÃ©todo 1: Local (Python)\r\n\r\n1. Clone o repositÃ³rio\r\n2. Instale as dependÃªncias:\r\n   ```bash\r\n   pip install -r requirements.txt\r\n   ```\r\n3. Configure o Ollama (certifique-se que estÃ¡ rodando)\r\n4. Execute o chat:\r\n   ```bash\r\n   chainlit run chainlit_chat.py --port 5003\r\n   ```\r\n\r\n### MÃ©todo 2: Docker Desktop\r\n\r\n1. Certifique-se que o Docker Desktop estÃ¡ instalado e rodando\r\n2. Certifique-se que o Ollama estÃ¡ rodando no host (Windows)\r\n3. Execute com docker-compose:\r\n   ```bash\r\n   docker-compose up -d\r\n   ```\r\n4. Acesse: http://localhost:5003\r\n\r\nPara parar o container:\r\n```bash\r\ndocker-compose down\r\n```\r\n\r\nPara reconstruir apÃ³s mudanÃ§as:\r\n```bash\r\ndocker-compose up -d --build\r\n```\r\n\r\n## âš™ï¸ ConfiguraÃ§Ã£o\r\n\r\nO projeto utiliza as seguintes variÃ¡veis de ambiente:\r\n\r\n- `OLLAMA_URL`: URL do Ollama (padrÃ£o: http://localhost:11434)\r\n  - No Docker: use `http://host.docker.internal:11434` para acessar o Ollama rodando no Windows\r\n- `OLLAMA_MODEL`: Modelo a ser usado (padrÃ£o: llama3.1:8b-instruct-q5_K_M)\r\n- `CHAT_LANGUAGE`: Idioma da interface (padrÃ£o: pt-BR)\r\n\r\n### ConfiguraÃ§Ã£o Docker\r\n\r\nAs variÃ¡veis podem ser ajustadas no arquivo `docker-compose.yml`:\r\n\r\n```yaml\r\nenvironment:\r\n  - OLLAMA_URL=http://host.docker.internal:11434\r\n  - OLLAMA_MODEL=llama3.1:8b-instruct-q5_K_M\r\n  - CHAT_LANGUAGE=pt-BR\r\n```\r\n\r\n## ğŸ“ Estrutura do Projeto\r\n\r\n```\r\nChat/\r\nâ”œâ”€â”€ chainlit_chat.py       # Arquivo principal da aplicaÃ§Ã£o\r\nâ”œâ”€â”€ chainlit.toml          # ConfiguraÃ§Ã£o do Chainlit\r\nâ”œâ”€â”€ chainlit.md            # PÃ¡gina inicial do chat (inglÃªs)\r\nâ”œâ”€â”€ chainlit_pt-BR.md      # PÃ¡gina inicial do chat (portuguÃªs)\r\nâ”œâ”€â”€ requirements.txt       # DependÃªncias Python\r\nâ”œâ”€â”€ Dockerfile             # ConfiguraÃ§Ã£o do container Docker\r\nâ”œâ”€â”€ docker-compose.yml     # OrquestraÃ§Ã£o Docker\r\nâ”œâ”€â”€ .dockerignore          # Arquivos ignorados no build Docker\r\nâ”œâ”€â”€ .chainlit/             # ConfiguraÃ§Ãµes internas do Chainlit\r\nâ”‚   â””â”€â”€ translations/      # TraduÃ§Ãµes customizadas da UI\r\nâ”‚       â””â”€â”€ pt-BR.json     # TraduÃ§Ã£o completa em portuguÃªs\r\nâ””â”€â”€ public/                # Arquivos estÃ¡ticos (CSS, JS, imagens)\r\n    â”œâ”€â”€ favicon.svg        # Favicon padrÃ£o (TAI)\r\n    â”œâ”€â”€ logo-mark.svg      # Logotipo em formato Ã­cone\r\n    â”œâ”€â”€ logo-light.svg     # Logotipo completo para fundo claro\r\n    â”œâ”€â”€ logo-dark.svg      # Logotipo completo para fundo escuro\r\n    â”œâ”€â”€ style.css          # Estilos personalizados\r\n    â””â”€â”€ translations/      # TraduÃ§Ãµes oficiais do Chainlit para referÃªncia\r\n```\r\n\r\n## ğŸ–¼ï¸ Identidade Visual\r\n\r\n- **Favicon:** `public/favicon.svg`\r\n- **Ãcone:** `public/logo-mark.svg`\r\n- **Logo (fundo claro):** `public/logo-light.svg`\r\n- **Logo (fundo escuro):** `public/logo-dark.svg`\r\n\r\nPara utilizar as artes no Chainlit, referencie-as no `chainlit.toml` ou diretamente no frontend com CSS/JS personalizados. Exemplos de configuraÃ§Ã£o:\r\n\r\n```toml\r\n[UI]\r\ncustom_css = \"/public/style.css\"\r\ncustom_js = \"/public/script.js\" # opcional, caso precise manipular dinamicamente a logo\r\n```\r\n\r\nNo CSS vocÃª pode apontar o logo padrÃ£o para o cabeÃ§alho:\r\n\r\n```css\r\n.MuiToolbar-root img {\r\n   content: url('/public/logo-light.svg');\r\n}\r\n\r\n@media (prefers-color-scheme: dark) {\r\n  .MuiToolbar-root img {\r\n     content: url('/public/logo-dark.svg');\r\n  }\r\n}\r\n```\r\n\r\n## ğŸ¯ Uso\r\n\r\n1. Inicie o Ollama em seu sistema\r\n2. Execute `chainlit run chainlit_chat.py`\r\n3. Abra o navegador no endereÃ§o indicado\r\n4. Comece a conversar!\r\n\r\n## ğŸŒ InternacionalizaÃ§Ã£o\r\n\r\n- `public/translations/` contÃ©m os arquivos oficiais de traduÃ§Ã£o do Chainlit.\r\n- Utilize-os como fallback para textos da interface ou para construir novas localizaÃ§Ãµes.\r\n- Se precisar personalizar termos, copie o arquivo de idioma desejado para `.chainlit/translations` e ajuste conforme necessÃ¡rio.\r\n\r\n## ğŸ¤– Sobre o Assistente\r\n\r\nO assistente (TAI) estÃ¡ configurado para fornecer informaÃ§Ãµes sobre sistemas ERP, emissÃ£o de notas fiscais (NF-e, NFC-e), vendas e cadastro de produtos.",
      "status": "processing",
      "created": "2025-10-04T22:45:27.858Z",
      "updated": "2025-10-04T22:45:27.858Z"
    }
  ]
]